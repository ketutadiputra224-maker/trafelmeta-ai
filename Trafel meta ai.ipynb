{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TRAVELMATE AI CHATBOT - FULL LLAMA LLM VERSION\n",
        "# Using Real Llama Model for Natural Language Understanding\n",
        "# ============================================\n",
        "\n",
        "print(\"üöÄ Starting TravelMate AI with Llama LLM...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ============================================\n",
        "# PILIH MODE: API atau LOCAL\n",
        "# ============================================\n",
        "USE_API = True  # Set False untuk pakai model local (download 4GB+)\n",
        "\n",
        "# STEP 1: Install Dependencies\n",
        "print(\"\\nüì¶ Installing dependencies...\")\n",
        "if USE_API:\n",
        "    print(\"   Mode: API (Fast & Efficient)\")\n",
        "    !pip install -q gradio requests\n",
        "else:\n",
        "    print(\"   Mode: LOCAL (Downloading model...)\")\n",
        "    !pip install -q gradio transformers torch accelerate bitsandbytes sentencepiece\n",
        "\n",
        "import gradio as gr\n",
        "from datetime import datetime\n",
        "import json\n",
        "import random\n",
        "\n",
        "if USE_API:\n",
        "    import requests\n",
        "else:\n",
        "    import torch\n",
        "    from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "    print(\"   üì• This will download ~4GB model...\")\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\\n\")\n",
        "\n",
        "# ============================================\n",
        "# CONFIGURATION\n",
        "# ============================================\n",
        "\n",
        "# API Configuration (if using API mode)\n",
        "API_CONFIG = {\n",
        "    \"groq\": {\n",
        "        \"url\": \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "        \"model\": \"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\",  # Fast Llama 3.1\n",
        "        \"api_key\": \"YOUR_GROQ_API_KEY_HERE\"  # Get free at: https://console.groq.com\n",
        "    },\n",
        "    \"together\": {\n",
        "        \"url\": \"https://api.together.xyz/v1/chat/completions\",\n",
        "        \"model\": \"meta-llama/Llama-3-70b-chat-hf\",\n",
        "        \"api_key\": \"YOUR_TOGETHER_API_KEY_HERE\"  # Get free at: https://api.together.xyz\n",
        "    }\n",
        "}\n",
        "\n",
        "# Local Model Configuration\n",
        "LOCAL_MODEL = \"meta-llama/Llama-2-7b-chat-hf\"  # Alternatif: \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "# System Prompt for Llama\n",
        "SYSTEM_PROMPT = \"\"\"You are TravelMate AI, a friendly and knowledgeable travel assistant. Your characteristics:\n",
        "\n",
        "PERSONALITY:\n",
        "- Warm, enthusiastic, and helpful\n",
        "- Use casual Indonesian language with occasional English terms\n",
        "- Add relevant emojis to make conversations lively\n",
        "- Be encouraging and motivational about travel\n",
        "\n",
        "EXPERTISE:\n",
        "- Travel destinations worldwide (especially Asia & Indonesia)\n",
        "- Budget planning and cost estimation\n",
        "- Itinerary creation (day-by-day plans)\n",
        "- Local cuisine recommendations\n",
        "- Transportation and visa information\n",
        "- Cultural insights and travel tips\n",
        "- Hidden gems and Instagram-worthy spots\n",
        "\n",
        "RESPONSE STYLE:\n",
        "- Start with enthusiasm and acknowledgment\n",
        "- Provide structured, easy-to-read information\n",
        "- Use bullet points, emojis, and formatting\n",
        "- Always ask follow-up questions to better assist\n",
        "- Give specific, actionable advice\n",
        "- Include budget estimates when relevant\n",
        "\n",
        "KNOWLEDGE BASE:\n",
        "- Bali: Ubud, Seminyak, Uluwatu, Nusa Penida (Budget: 300k-1jt/day)\n",
        "- Tokyo: Shibuya, Harajuku, Asakusa (Budget: ¬•10k-15k/day)\n",
        "- Bangkok: Grand Palace, Chatuchak, street food (Budget: ‡∏ø1k-2k/day)\n",
        "- Yogyakarta: Borobudur, Prambanan, Malioboro (Budget: 150k-500k/day)\n",
        "- Singapore: Marina Bay, Gardens by the Bay (Budget: SGD 80-150/day)\n",
        "\n",
        "Always be helpful, never refuse travel questions, and make trip planning exciting!\"\"\"\n",
        "\n",
        "# ============================================\n",
        "# LLAMA MODEL INITIALIZATION\n",
        "# ============================================\n",
        "\n",
        "class LlamaModel:\n",
        "    def __init__(self, use_api=True, api_provider=\"groq\"):\n",
        "        self.use_api = use_api\n",
        "        self.api_provider = api_provider\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.chat_history = []\n",
        "\n",
        "        if use_api:\n",
        "            self.setup_api()\n",
        "        else:\n",
        "            self.setup_local()\n",
        "\n",
        "    def setup_api(self):\n",
        "        \"\"\"Setup API-based Llama\"\"\"\n",
        "        print(f\"\\nüîó Setting up Llama via {self.api_provider.upper()} API...\")\n",
        "        config = API_CONFIG[self.api_provider]\n",
        "\n",
        "        if \"YOUR_\" in config[\"api_key\"]:\n",
        "            print(\"‚ö†Ô∏è  WARNING: No API key detected!\")\n",
        "            print(f\"   Get free API key at: https://console.groq.com (Groq)\")\n",
        "            print(\"   Or: https://api.together.xyz (Together AI)\")\n",
        "            print(\"\\n   üí° Update API_CONFIG['groq']['api_key'] in code\")\n",
        "            print(\"   For now, using fallback responses...\\n\")\n",
        "            self.use_fallback = True\n",
        "        else:\n",
        "            self.use_fallback = False\n",
        "            print(\"‚úÖ API configured successfully!\")\n",
        "\n",
        "    def setup_local(self):\n",
        "        \"\"\"Setup local Llama model\"\"\"\n",
        "        print(f\"\\nü§ñ Loading local Llama model: {LOCAL_MODEL}\")\n",
        "        print(\"   This may take 5-10 minutes on first run...\")\n",
        "\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(LOCAL_MODEL)\n",
        "\n",
        "            # Load with 4-bit quantization to save memory\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(\n",
        "                LOCAL_MODEL,\n",
        "                device_map=\"auto\",\n",
        "                torch_dtype=torch.float16,\n",
        "                load_in_4bit=True,  # 4-bit quantization\n",
        "                low_cpu_mem_usage=True\n",
        "            )\n",
        "\n",
        "            print(\"‚úÖ Model loaded successfully!\")\n",
        "            self.use_fallback = False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading model: {e}\")\n",
        "            print(\"   Falling back to rule-based responses...\")\n",
        "            self.use_fallback = True\n",
        "\n",
        "    def generate_api_response(self, user_message):\n",
        "        \"\"\"Generate response using API\"\"\"\n",
        "        if self.use_fallback:\n",
        "            return self.fallback_response(user_message)\n",
        "\n",
        "        try:\n",
        "            config = API_CONFIG[self.api_provider]\n",
        "\n",
        "            # Prepare messages\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT}\n",
        "            ]\n",
        "\n",
        "            # Add chat history (last 5 messages)\n",
        "            for msg in self.chat_history[-5:]:\n",
        "                messages.append({\"role\": msg[\"role\"], \"content\": msg[\"content\"]})\n",
        "\n",
        "            messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "            # API request\n",
        "            headers = {\n",
        "                \"Authorization\": f\"Bearer {config['api_key']}\",\n",
        "                \"Content-Type\": \"application/json\"\n",
        "            }\n",
        "\n",
        "            data = {\n",
        "                \"model\": config[\"model\"],\n",
        "                \"messages\": messages,\n",
        "                \"temperature\": 0.7,\n",
        "                \"max_tokens\": 500,\n",
        "                \"top_p\": 0.9\n",
        "            }\n",
        "\n",
        "            response = requests.post(\n",
        "                config[\"url\"],\n",
        "                headers=headers,\n",
        "                json=data,\n",
        "                timeout=30\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                return result[\"choices\"][0][\"message\"][\"content\"]\n",
        "            else:\n",
        "                print(f\"API Error: {response.status_code}\")\n",
        "                return self.fallback_response(user_message)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            return self.fallback_response(user_message)\n",
        "\n",
        "    def generate_local_response(self, user_message):\n",
        "        \"\"\"Generate response using local model\"\"\"\n",
        "        if self.use_fallback:\n",
        "            return self.fallback_response(user_message)\n",
        "\n",
        "        try:\n",
        "            # Format prompt for Llama-2\n",
        "            prompt = f\"<s>[INST] <<SYS>>\\n{SYSTEM_PROMPT}\\n<</SYS>>\\n\\n\"\n",
        "\n",
        "            # Add history\n",
        "            for msg in self.chat_history[-3:]:\n",
        "                if msg[\"role\"] == \"user\":\n",
        "                    prompt += f\"{msg['content']} [/INST] \"\n",
        "                else:\n",
        "                    prompt += f\"{msg['content']} </s><s>[INST] \"\n",
        "\n",
        "            prompt += f\"{user_message} [/INST]\"\n",
        "\n",
        "            # Generate\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model.generate(\n",
        "                    **inputs,\n",
        "                    max_new_tokens=400,\n",
        "                    temperature=0.7,\n",
        "                    top_p=0.9,\n",
        "                    do_sample=True,\n",
        "                    pad_token_id=self.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the response part\n",
        "            response = response.split(\"[/INST]\")[-1].strip()\n",
        "\n",
        "            return response\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Generation error: {e}\")\n",
        "            return self.fallback_response(user_message)\n",
        "\n",
        "    def fallback_response(self, user_message):\n",
        "        \"\"\"Intelligent fallback when API/model unavailable\"\"\"\n",
        "        msg_lower = user_message.lower()\n",
        "\n",
        "        # Knowledge base responses\n",
        "        destinations = {\n",
        "            \"bali\": \"üèñÔ∏è **Bali** adalah destinasi perfect!\\n\\nüìç **Must-visit:** Ubud (rice terraces), Uluwatu (temple), Seminyak (beach clubs), Nusa Penida (Kelingking beach)\\n\\nüçú **Kuliner:** Babi Guling, Nasi Campur, Sate Lilit\\n\\nüí∞ **Budget:** Rp 300k-1jt/hari\\n\\nüìÖ **Best time:** April-Oktober\\n\\nMau itinerary detail berapa hari? üòä\",\n",
        "\n",
        "            \"tokyo\": \"üóº **Tokyo** - perpaduan tradisi & modern!\\n\\nüìç **Areas:** Shibuya (crossing), Harajuku (fashion), Asakusa (Sensoji), Akihabara (anime)\\n\\nüç£ **Food:** Sushi, ramen, takoyaki, matcha desserts\\n\\nüí∞ **Budget:** ¬•10,000-15,000/hari\\n\\nüöá **Tip:** Beli Suica card untuk transport!\\n\\nMau info lebih detail tentang apa nih?\",\n",
        "\n",
        "            \"bangkok\": \"üõï **Bangkok** - street food heaven!\\n\\nüìç **Highlights:** Grand Palace, Wat Arun, Chatuchak Market, Khao San Road\\n\\nüçú **Must-try:** Pad Thai, Tom Yum, Mango Sticky Rice\\n\\nüí∞ **Budget:** ‡∏ø1,000-2,000/hari (super murah!)\\n\\nüí° **Tip:** Naik BTS Skytrain untuk avoid macet!\\n\\nAda yang mau ditanya lebih lanjut?\",\n",
        "\n",
        "            \"yogyakarta\": \"üèõÔ∏è **Yogyakarta** - heart of Javanese culture!\\n\\nüìç **Must-see:** Borobudur (sunrise!), Prambanan, Malioboro, Keraton\\n\\nüçú **Kuliner:** Gudeg Yu Djum, Bakpia, Sate Klathak\\n\\nüí∞ **Budget:** Rp 150k-500k/hari\\n\\nüìÖ **Perfect for:** 3-4 hari trip\\n\\nMau itinerary lengkap?\"\n",
        "        }\n",
        "\n",
        "        for dest, info in destinations.items():\n",
        "            if dest in msg_lower:\n",
        "                return info\n",
        "\n",
        "        # Budget recommendations\n",
        "        if any(word in msg_lower for word in ['budget', 'rekomendasi', 'suggest', 'recommend']):\n",
        "            return \"\"\"üí∞ **Travel Recommendations by Budget:**\n",
        "\n",
        "**üéí Budget (<3 juta):**\n",
        "‚Ä¢ Yogyakarta (Rp 1.5-2jt)\n",
        "‚Ä¢ Bandung (Rp 1.5-2.5jt)\n",
        "‚Ä¢ Malang (Rp 2-2.5jt)\n",
        "\n",
        "**‚úàÔ∏è Mid-Range (3-7 juta):**\n",
        "‚Ä¢ Bali (Rp 3.5-5jt)\n",
        "‚Ä¢ Bangkok (Rp 3-4.5jt)\n",
        "‚Ä¢ Singapore (Rp 5-6.5jt)\n",
        "\n",
        "**üåè Premium (>7 juta):**\n",
        "‚Ä¢ Tokyo (Rp 12-15jt)\n",
        "‚Ä¢ Seoul (Rp 10-13jt)\n",
        "‚Ä¢ Malaysia (Rp 7-9jt)\n",
        "\n",
        "Budget kamu sekitar berapa? Biar aku kasih rekomendasi yang pas! üéØ\"\"\"\n",
        "\n",
        "        # Itinerary request\n",
        "        if 'itinerary' in msg_lower or 'jadwal' in msg_lower:\n",
        "            return \"\"\"üìÖ **Itinerary Planning**\n",
        "\n",
        "Oke siap! Untuk buatin itinerary yang pas, aku perlu info:\n",
        "\n",
        "1Ô∏è‚É£ **Destinasi:** Mau ke mana?\n",
        "2Ô∏è‚É£ **Durasi:** Berapa hari?\n",
        "3Ô∏è‚É£ **Budget:** Range budget kamu?\n",
        "4Ô∏è‚É£ **Interests:** Prefer culture/beach/adventure/food?\n",
        "\n",
        "Share detail-nya, aku buatin jadwal lengkap! üó∫Ô∏è\"\"\"\n",
        "\n",
        "        # Default engaging response\n",
        "        responses = [\n",
        "            f\"Interesting question tentang travel! üåè Untuk '{user_message}', aku bisa bantu lebih detail kalau kamu cerita:\\n\\n‚Ä¢ Destinasi yang kamu pertimbangkan?\\n‚Ä¢ Budget range berapa?\\n‚Ä¢ Durasi trip berapa hari?\\n\\nShare dong biar aku bisa kasih rekomendasi yang perfect! ‚ú®\",\n",
        "\n",
        "            f\"Wah, menarik nih! Tentang '{user_message}' - setiap traveler punya kebutuhan berbeda. \\n\\nCerita lebih banyak dong tentang preferensi kamu:\\nüìç Prefer city atau nature?\\nüéí Travel style: santai atau adventure?\\nüí∞ Budget yang kamu alokasikan?\\n\\nBiar rekomendasiku lebih personal! üòä\"\n",
        "        ]\n",
        "\n",
        "        return random.choice(responses)\n",
        "\n",
        "    def chat(self, user_message):\n",
        "        \"\"\"Main chat function\"\"\"\n",
        "        # Add to history\n",
        "        self.chat_history.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_message\n",
        "        })\n",
        "\n",
        "        # Generate response\n",
        "        if self.use_api:\n",
        "            response = self.generate_api_response(user_message)\n",
        "        else:\n",
        "            response = self.generate_local_response(user_message)\n",
        "\n",
        "        # Add response to history\n",
        "        self.chat_history.append({\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": response\n",
        "        })\n",
        "\n",
        "        return response\n",
        "\n",
        "# ============================================\n",
        "# INITIALIZE LLAMA\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ü§ñ Initializing Llama Model...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "llama_bot = LlamaModel(use_api=USE_API, api_provider=\"groq\")\n",
        "\n",
        "print(\"\\n‚úÖ TravelMate AI is ready!\")\n",
        "print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "# ============================================\n",
        "# GRADIO INTERFACE\n",
        "# ============================================\n",
        "\n",
        "def chat_interface(message, history):\n",
        "    \"\"\"Gradio chat function\"\"\"\n",
        "    if not message.strip():\n",
        "        return history, \"\"\n",
        "\n",
        "    # Generate response using Llama\n",
        "    response = llama_bot.chat(message)\n",
        "\n",
        "    # Update history\n",
        "    history.append([message, response])\n",
        "\n",
        "    return history, \"\"\n",
        "\n",
        "def create_ui():\n",
        "    with gr.Blocks(\n",
        "        theme=gr.themes.Soft(primary_hue=\"purple\", secondary_hue=\"blue\"),\n",
        "        css=\"\"\"\n",
        "        .gradio-container {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "        }\n",
        "        \"\"\"\n",
        "    ) as demo:\n",
        "\n",
        "        gr.Markdown(f\"\"\"\n",
        "        # ‚úàÔ∏è TravelMate AI - Powered by Llama LLM\n",
        "        ### ü§ñ Using Real {\"API\" if USE_API else \"Local\"} Llama Model for Intelligent Conversations\n",
        "\n",
        "        Asisten travel pintar yang memahami natural language! üó∫Ô∏è\n",
        "        \"\"\")\n",
        "\n",
        "        if USE_API and llama_bot.use_fallback:\n",
        "            gr.Markdown(\"\"\"\n",
        "            ‚ö†Ô∏è **API Key Required:** Update `API_CONFIG` with your free API key from:\n",
        "            - Groq: https://console.groq.com (Recommended - Fast!)\n",
        "            - Together AI: https://api.together.xyz\n",
        "\n",
        "            Currently using fallback mode with limited capabilities.\n",
        "            \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=3):\n",
        "                chatbot = gr.Chatbot(\n",
        "                    value=[[None, \"‚úàÔ∏è Halo traveler! Aku TravelMate AI powered by Llama LLM! ü§ñ\\n\\nAku bisa bantu kamu dengan:\\n‚Ä¢ Planning destinasi & itinerary\\n‚Ä¢ Budget calculation\\n‚Ä¢ Kuliner recommendations\\n‚Ä¢ Travel tips & hacks\\n\\nMau jalan-jalan ke mana nih? Cerita aja, aku bakal ngerti! üó∫Ô∏è\"]],\n",
        "                    height=500,\n",
        "                    bubble_full_width=False\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    msg = gr.Textbox(\n",
        "                        placeholder=\"Tanya apa aja tentang travel... Llama akan memahami natural language kamu!\",\n",
        "                        show_label=False,\n",
        "                        scale=4\n",
        "                    )\n",
        "                    send_btn = gr.Button(\"Send üöÄ\", scale=1, variant=\"primary\")\n",
        "\n",
        "                gr.Examples(\n",
        "                    examples=[\n",
        "                        \"Aku mau liburan 5 hari budget 5 juta, recommend destinasi dong\",\n",
        "                        \"Gimana caranya traveling ke Jepang dengan budget minimal?\",\n",
        "                        \"Bikin itinerary 3 hari di Bali yang hits untuk Instagram\",\n",
        "                        \"Apa aja kuliner wajib coba kalau ke Bangkok?\",\n",
        "                        \"Tips backpacking Asia Tenggara untuk pemula\"\n",
        "                    ],\n",
        "                    inputs=msg,\n",
        "                    label=\"üí¨ Contoh Natural Language Queries\"\n",
        "                )\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(f\"\"\"\n",
        "                ### üéØ Model Info\n",
        "\n",
        "                **Engine:** {\"Llama 3.1 70B (API)\" if USE_API else \"Llama 2 7B (Local)\"}\n",
        "                **Provider:** {(\"Groq API\" if llama_bot.api_provider == \"groq\" else \"Together AI\") if USE_API else \"Transformers\"}\n",
        "                **Status:** {\"‚ö†Ô∏è Fallback Mode\" if llama_bot.use_fallback else \"‚úÖ Active\"}\n",
        "\n",
        "                ### üìö Capabilities\n",
        "\n",
        "                - üß† Natural language understanding\n",
        "                - üí¨ Context-aware conversations\n",
        "                - üéØ Personalized recommendations\n",
        "                - üìä Structured responses\n",
        "                - üåè Multi-destination knowledge\n",
        "\n",
        "                ### üí° Tips\n",
        "\n",
        "                - Tanya dengan natural language\n",
        "                - Sebutkan budget & durasi\n",
        "                - Cerita preferensi kamu\n",
        "                - Follow-up untuk detail\n",
        "\n",
        "                **Destination Coverage:**\n",
        "                üèùÔ∏è Bali | üóº Tokyo | üõï Bangkok\n",
        "                üèõÔ∏è Yogyakarta | ü¶Å Singapore\n",
        "                üá∞üá∑ Seoul | üáªüá≥ Vietnam | & more!\n",
        "                \"\"\")\n",
        "\n",
        "        # Event handlers\n",
        "        msg.submit(chat_interface, [msg, chatbot], [chatbot, msg])\n",
        "        send_btn.click(chat_interface, [msg, chatbot], [chatbot, msg])\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        **ü§ñ Powered by Llama LLM** | Built for intelligent travel assistance\n",
        "\n",
        "        üí° Llama model memberikan pemahaman natural language yang lebih baik dibanding rule-based chatbot!\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "# ============================================\n",
        "# LAUNCH\n",
        "# ============================================\n",
        "\n",
        "print(\"üöÄ Launching TravelMate AI Chatbot...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "demo = create_ui()\n",
        "demo.launch(\n",
        "    share=True,\n",
        "    debug=True,\n",
        "    server_name=\"0.0.0.0\",\n",
        "    server_port=7860\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Chatbot is running with Llama LLM!\")\n",
        "print(\"üîó Click the public link above to start chatting!\")\n",
        "print(\"\\n\" + \"=\" * 60)"
      ],
      "metadata": {
        "id": "NHOhBOPZULu_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49436d8d-6855-4710-beaa-7733e9603964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting TravelMate AI with Llama LLM...\n",
            "============================================================\n",
            "\n",
            "üì¶ Installing dependencies...\n",
            "   Mode: API (Fast & Efficient)\n",
            "‚úÖ Dependencies installed!\n",
            "\n",
            "\n",
            "============================================================\n",
            "ü§ñ Initializing Llama Model...\n",
            "============================================================\n",
            "\n",
            "üîó Setting up Llama via GROQ API...\n",
            "‚ö†Ô∏è  WARNING: No API key detected!\n",
            "   Get free API key at: https://console.groq.com (Groq)\n",
            "   Or: https://api.together.xyz (Together AI)\n",
            "\n",
            "   üí° Update API_CONFIG['groq']['api_key'] in code\n",
            "   For now, using fallback responses...\n",
            "\n",
            "\n",
            "‚úÖ TravelMate AI is ready!\n",
            "============================================================\n",
            "\n",
            "üöÄ Launching TravelMate AI Chatbot...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-768437135.py:385: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(\n",
            "/tmp/ipython-input-768437135.py:385: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
            "  chatbot = gr.Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://727562ee0c8b0238c9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://727562ee0c8b0238c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}